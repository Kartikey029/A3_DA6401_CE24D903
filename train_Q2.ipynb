{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e762738f-3716-48e5-91bc-279a5e0aace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import os\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Character-level dataset class\n",
    "class TransliterationDataset(Dataset):\n",
    "    def __init__(self, data_file, max_len=500):\n",
    "        self.df = pd.read_csv(data_file, sep='\\t', header=None)\n",
    "        self.src_texts = self.df[1].astype(str).tolist()\n",
    "        self.tgt_texts = self.df[0].astype(str).tolist()\n",
    "        self.max_len = max_len\n",
    "        self.src_vocab = self.build_vocab(self.src_texts)\n",
    "        self.tgt_vocab = self.build_vocab(self.tgt_texts)\n",
    "        self.src_vocab_size = len(self.src_vocab)\n",
    "        self.tgt_vocab_size = len(self.tgt_vocab)\n",
    "        self.src_pad_idx = self.src_vocab['<pad>']\n",
    "        self.tgt_pad_idx = self.tgt_vocab['<pad>']\n",
    "        self.tgt_sos_idx = self.tgt_vocab['<sos>']\n",
    "        self.tgt_eos_idx = self.tgt_vocab['<eos>']\n",
    "        self.tgt_inv_vocab = {i: char for char, i in self.tgt_vocab.items()}\n",
    "        self.src_inv_vocab = {i: char for char, i in self.src_vocab.items()}\n",
    "    \n",
    "    def build_vocab(self, texts):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            counter.update(list(text))\n",
    "        vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "        vocab.update({char: i+3 for i, char in enumerate(sorted(counter.keys()))})\n",
    "        return vocab\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.src_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src_texts[idx]\n",
    "        tgt = self.tgt_texts[idx]\n",
    "        src_indices = [self.src_vocab[char] for char in src if char in self.src_vocab]\n",
    "        tgt_indices = [self.tgt_sos_idx] + [self.tgt_vocab[char] for char in tgt if char in self.tgt_vocab] + [self.tgt_eos_idx]\n",
    "        return torch.tensor(src_indices), torch.tensor(tgt_indices), src, tgt\n",
    "\n",
    "# # Attention layer (Bahdanau)\n",
    "# class Attention(nn.Module):\n",
    "#     def __init__(self, hid_dim):\n",
    "#         super().__init__()\n",
    "#         self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
    "#         self.v = nn.Parameter(torch.rand(hid_dim))\n",
    "#         nn.init.normal_(self.v, 0, 0.1)\n",
    "#         nn.init.xavier_uniform_(self.attn.weight)\n",
    "    \n",
    "#     def forward(self, hidden, encoder_outputs):\n",
    "#         src_len = encoder_outputs.shape[0]\n",
    "#         hidden = hidden.unsqueeze(0).repeat(src_len, 1, 1)\n",
    "#         energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "#         energy = energy.permute(1, 0, 2)\n",
    "#         v = self.v.repeat(encoder_outputs.size(1), 1).unsqueeze(1)\n",
    "#         attention = torch.bmm(energy, v).squeeze(2)\n",
    "#         return torch.softmax(attention, dim=1)\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
    "        self.v = nn.Parameter(torch.rand(hid_dim))\n",
    "        nn.init.normal_(self.v, 0, 0.1)\n",
    "        nn.init.xavier_uniform_(self.attn.weight)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        hidden = hidden.unsqueeze(0).repeat(src_len, 1, 1)  # [src_len, batch_size, hid_dim]\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [src_len, batch_size, hid_dim]\n",
    "        energy = energy.permute(1, 0, 2)  # [batch_size, src_len, hid_dim]\n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(2)  # [batch_size, hid_dim, 1]\n",
    "        attention = torch.bmm(energy, v).squeeze(2)  # [batch_size, src_len]\n",
    "        return torch.softmax(attention, dim=1)\n",
    "# Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, cell_type, dropout, bidirectional):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.cell_type = cell_type\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_class(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        if self.cell_type == 'LSTM':\n",
    "            outputs, (hidden, cell) = self.rnn(embedded)\n",
    "            return outputs, hidden, cell\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedded)\n",
    "            return outputs, hidden\n",
    "\n",
    "# Decoder with Attention\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, cell_type, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.cell_type = cell_type\n",
    "        self.hid_dim = hid_dim\n",
    "        self.attention = attention\n",
    "        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_class(hid_dim + emb_dim, hid_dim, num_layers=n_layers, dropout=dropout if n_layers > 1 else 0)\n",
    "        self.fc_out = nn.Linear(hid_dim * 2 + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        a = self.attention(hidden[-1], encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        context = torch.bmm(a, encoder_outputs)\n",
    "        context = context.permute(1, 0, 2)\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "        if self.cell_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        else:\n",
    "            output, hidden = self.rnn(rnn_input, hidden)\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        context = context.squeeze(0)\n",
    "        prediction = self.fc_out(torch.cat((output, context, embedded), dim=1))\n",
    "        return prediction, hidden, cell, a.squeeze(1)\n",
    "\n",
    "# Seq2Seq with Attention\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        attention_weights = torch.zeros(trg_len, batch_size, src.shape[0]).to(self.device)\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        else:\n",
    "            encoder_outputs, hidden = self.encoder(src)\n",
    "            cell = None\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell, attn = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            attention_weights[t] = attn\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs, attention_weights\n",
    "    \n",
    "    def predict(self, src, max_len=50, sos_idx=1, eos_idx=2):\n",
    "        self.eval()\n",
    "        src = src.to(self.device)\n",
    "        batch_size = src.shape[1] if len(src.shape) > 1 else 1\n",
    "        outputs = torch.zeros(max_len, batch_size).long().to(self.device)\n",
    "        attention_weights = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n",
    "        outputs[0] = sos_idx\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        else:\n",
    "            encoder_outputs, hidden = self.encoder(src)\n",
    "            cell = None\n",
    "        input = torch.LongTensor([sos_idx] * batch_size).to(self.device)\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, cell, attn = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            attention_weights[t] = attn\n",
    "            top1 = output.argmax(1)\n",
    "            outputs[t] = top1\n",
    "            input = top1\n",
    "            if all(top1 == eos_idx):\n",
    "                outputs = outputs[:t+1]\n",
    "                attention_weights = attention_weights[:t+1]\n",
    "                break\n",
    "        return outputs, attention_weights\n",
    "\n",
    "# Accuracy metrics\n",
    "def calculate_accuracies(model, iterator, device, dataset, max_len=50):\n",
    "    model.eval()\n",
    "    char_correct = 0\n",
    "    char_total = 0\n",
    "    word_correct = 0\n",
    "    word_total = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, src_text, tgt_text in iterator:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output, _ = model.predict(src, max_len, dataset.tgt_sos_idx, dataset.tgt_eos_idx)\n",
    "            for i in range(src.shape[1]):\n",
    "                pred_seq = output[:, i].cpu().numpy()\n",
    "                trg_seq = trg[:, i].cpu().numpy()\n",
    "                pred_chars = [dataset.tgt_inv_vocab.get(idx, '<unk>') for idx in pred_seq \n",
    "                              if idx not in [dataset.tgt_eos_idx, dataset.tgt_pad_idx, dataset.tgt_sos_idx]]\n",
    "                trg_chars = [dataset.tgt_inv_vocab.get(idx, '<unk>') for idx in trg_seq \n",
    "                             if idx not in [dataset.tgt_eos_idx, dataset.tgt_pad_idx, dataset.tgt_sos_idx]]\n",
    "                char_correct += sum(p == t for p, t in zip(pred_chars, trg_chars))\n",
    "                char_total += len(trg_chars)\n",
    "                pred_word = ''.join(pred_chars)\n",
    "                trg_word = ''.join(trg_chars)\n",
    "                word_correct += pred_word == trg_word\n",
    "                word_total += 1\n",
    "    char_acc = char_correct / char_total if char_total > 0 else 0\n",
    "    word_acc = word_correct / word_total if word_total > 0 else 0\n",
    "    return char_acc, word_acc\n",
    "\n",
    "# Training function\n",
    "def train(model, iterator, optimizer, criterion, clip, device, dataset):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg, _, _ in iterator:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    char_acc, word_acc = calculate_accuracies(model, iterator, device, dataset)\n",
    "    return epoch_loss / len(iterator), char_acc, word_acc\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, iterator, criterion, device, dataset):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, _, _ in iterator:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output, _ = model(src, trg, 0)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    char_acc, word_acc = calculate_accuracies(model, iterator, device, dataset)\n",
    "    return epoch_loss / len(iterator), char_acc, word_acc\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    src_tensors, tgt_tensors, src_texts, tgt_texts = zip(*batch)\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_tensors, batch_first=False, padding_value=0)\n",
    "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_tensors, batch_first=False, padding_value=0)\n",
    "    return src_padded, tgt_padded, list(src_texts), list(tgt_texts)\n",
    "\n",
    "# Generate attention heatmaps\n",
    "def plot_attention_heatmaps(samples, dataset, save_dir='predictions_attention'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    for i, sample in enumerate(samples[:9]):\n",
    "        src_text = sample['Latin Input']\n",
    "        tgt_text = sample['Devanagari Target']\n",
    "        pred_text = sample['Devanagari Predicted']\n",
    "        attn = sample['Attention Weights'].cpu().numpy()\n",
    "        src_chars = [dataset.src_inv_vocab.get(idx, '<unk>') for idx in sample['Src Indices'] \n",
    "                     if idx not in [dataset.src_eos_idx, dataset.src_pad_idx]]\n",
    "        tgt_chars = [dataset.tgt_inv_vocab.get(idx, '<unk>') for idx in sample['Pred Indices'] \n",
    "                     if idx not in [dataset.tgt_eos_idx, dataset.tgt_pad_idx, dataset.tgt_sos_idx]]\n",
    "        sns.heatmap(attn[:len(tgt_chars), :len(src_chars)], ax=axes[i], cmap='viridis', \n",
    "                    xticklabels=src_chars, yticklabels=tgt_chars, cbar=False)\n",
    "        axes[i].set_title(f'Input: {src_text}\\nPred: {pred_text}\\nCorrect: {\"✅\" if sample[\"Correct\"] else \"❌\"}')\n",
    "        axes[i].set_xlabel('Source (Latin)')\n",
    "        axes[i].set_ylabel('Target (Devanagari)')\n",
    "    for j in range(len(samples), 9):\n",
    "        axes[j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'attention_heatmaps.png'))\n",
    "    plt.close()\n",
    "    wandb.log({'attention_heatmaps': wandb.Image(os.path.join(save_dir, 'attention_heatmaps.png'))})\n",
    "\n",
    "# Training function for WandB sweep\n",
    "def train_sweep():\n",
    "    wandb.init()\n",
    "    hparams = wandb.config\n",
    "    \n",
    "    base_path = '/home/user/Downloads/dakshina_dataset_v1.0/hi/lexicons'\n",
    "    train_path = f'{base_path}/hi.translit.sampled.train.tsv'\n",
    "    dev_path = f'{base_path}/hi.translit.sampled.dev.tsv'\n",
    "    test_path = f'{base_path}/hi.translit.sampled.test.tsv'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    train_dataset = TransliterationDataset(train_path)\n",
    "    dev_dataset = TransliterationDataset(dev_path)\n",
    "    test_dataset = TransliterationDataset(test_path)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=hparams.batch_size, shuffle=True, \n",
    "                             collate_fn=collate_fn)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=hparams.batch_size, \n",
    "                           collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=hparams.batch_size, \n",
    "                            collate_fn=collate_fn)\n",
    "    \n",
    "    # Debug: Print sample batch\n",
    "    for src, trg, src_text, tgt_text in train_loader:\n",
    "        print(f\"Sample batch: src shape={src.shape}, trg shape={trg.shape}, src_text={src_text[:2]}, tgt_text={tgt_text[:2]}\")\n",
    "        break\n",
    "    \n",
    "    attention = Attention(hparams.hid_dim)\n",
    "    encoder = Encoder(\n",
    "        input_dim=train_dataset.src_vocab_size,\n",
    "        emb_dim=hparams.emb_dim,\n",
    "        hid_dim=hparams.hid_dim,\n",
    "        n_layers=hparams.enc_layers,\n",
    "        cell_type=hparams.cell_type,\n",
    "        dropout=hparams.dropout,\n",
    "        bidirectional=hparams.bidirectional\n",
    "    )\n",
    "    decoder = Decoder(\n",
    "        output_dim=train_dataset.tgt_vocab_size,\n",
    "        emb_dim=hparams.emb_dim,\n",
    "        hid_dim=hparams.hid_dim,\n",
    "        n_layers=hparams.dec_layers,\n",
    "        cell_type=hparams.cell_type,\n",
    "        dropout=hparams.dropout,\n",
    "        attention=attention\n",
    "    )\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    \n",
    "    optimizer_class = {'Adam': optim.Adam, 'RMSprop': optim.RMSprop, 'AdamW': optim.AdamW}[hparams.optimizer]\n",
    "    optimizer = optimizer_class(model.parameters(), lr=hparams.learning_rate, weight_decay=hparams.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=train_dataset.tgt_pad_idx)\n",
    "    \n",
    "    n_epochs = 25\n",
    "    best_valid_word_acc = 0\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss, train_char_acc, train_word_acc = train(model, train_loader, optimizer, \n",
    "                                                              criterion, hparams.grad_clip, device, train_dataset)\n",
    "            valid_loss, valid_char_acc, valid_word_acc = evaluate(model, dev_loader, criterion, device, dev_dataset)\n",
    "            wandb.log({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'train_char_acc': train_char_acc,\n",
    "                'train_word_acc': train_word_acc,\n",
    "                'valid_loss': valid_loss,\n",
    "                'valid_char_acc': valid_char_acc,\n",
    "                'valid_word_acc': valid_word_acc\n",
    "            })\n",
    "            print(f'Epoch: {epoch+1:02}')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Char Acc: {train_char_acc:.3f} | Word Acc: {train_word_acc:.3f}')\n",
    "            print(f'\\tVal. Loss: {valid_loss:.3f} | Char Acc: {valid_char_acc:.3f} | Word Acc: {valid_word_acc:.3f}')\n",
    "            if valid_word_acc > best_valid_word_acc:\n",
    "                best_valid_word_acc = valid_word_acc\n",
    "                torch.save(model.state_dict(), f'best_model_{wandb.run.id}.pt')\n",
    "                artifact = wandb.Artifact(f'model_{wandb.run.id}', type='model')\n",
    "                artifact.add_file(f'best_model_{wandb.run.id}.pt')\n",
    "                wandb.log_artifact(artifact)\n",
    "        \n",
    "        model.load_state_dict(torch.load(f'best_model_{wandb.run.id}.pt'))\n",
    "        test_loss, test_char_acc, test_word_acc = evaluate(model, test_loader, criterion, device, test_dataset)\n",
    "        wandb.log({\n",
    "            'test_loss': test_loss,\n",
    "            'test_char_acc': test_char_acc,\n",
    "            'test_word_acc': test_word_acc\n",
    "        })\n",
    "        print(f'\\nTest Results:')\n",
    "        print(f'\\tTest Loss: {test_loss:.3f}')\n",
    "        print(f'\\tTest Char Accuracy: {test_char_acc:.3f}')\n",
    "        print(f'\\tTest Word Accuracy: {test_word_acc:.3f}')\n",
    "        \n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        heatmap_samples = []\n",
    "        with torch.no_grad():\n",
    "            for src, trg, src_text, tgt_text in test_loader:\n",
    "                src = src.to(device)\n",
    "                output, attn_weights = model.predict(src, max_len=50, \n",
    "                                                    sos_idx=test_dataset.tgt_sos_idx, \n",
    "                                                    eos_idx=test_dataset.tgt_eos_idx)\n",
    "                for i in range(src.shape[1]):\n",
    "                    pred_seq = output[:, i].cpu().numpy()\n",
    "                    pred_word = ''.join([test_dataset.tgt_inv_vocab.get(idx, '<unk>') for idx in pred_seq \n",
    "                                        if idx not in [test_dataset.tgt_eos_idx, test_dataset.tgt_pad_idx, test_dataset.tgt_sos_idx]])\n",
    "                    all_predictions.append({\n",
    "                        'Latin Input': src_text[i],\n",
    "                        'Devanagari Target': tgt_text[i],\n",
    "                        'Devanagari Predicted': pred_word,\n",
    "                        'Correct': pred_word == tgt_text[i]\n",
    "                    })\n",
    "                    if len(heatmap_samples) < 10:\n",
    "                        heatmap_samples.append({\n",
    "                            'Latin Input': src_text[i],\n",
    "                            'Devanagari Target': tgt_text[i],\n",
    "                            'Devanagari Predicted': pred_word,\n",
    "                            'Correct': pred_word == tgt_text[i],\n",
    "                            'Src Indices': src[:, i].cpu().numpy(),\n",
    "                            'Pred Indices': pred_seq,\n",
    "                            'Attention Weights': attn_weights[:, i, :]\n",
    "                        })\n",
    "        \n",
    "        os.makedirs('predictions_attention', exist_ok=True)\n",
    "        predictions_df = pd.DataFrame(all_predictions)\n",
    "        predictions_df.to_csv('predictions_attention/test_predictions.csv', index=False)\n",
    "        \n",
    "        plot_attention_heatmaps(heatmap_samples, test_dataset)\n",
    "        \n",
    "        headers = ['#', 'Latin Input', 'Devanagari Target', 'Devanagari Predicted', 'Correct']\n",
    "        table_data = [[i+1, s['Latin Input'], s['Devanagari Target'], s['Devanagari Predicted'], \n",
    "                       '✅' if s['Correct'] else '❌'] for i, s in enumerate(all_predictions[:5])]\n",
    "        wandb.log({'sample_predictions': wandb.Table(columns=headers, data=table_data)})\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"Training interrupted. Saving current model state...\")\n",
    "        torch.save(model.state_dict(), f'last_model_{wandb.run.id}.pt')\n",
    "        artifact = wandb.Artifact(f'last_model_{wandb.run.id}', type='model')\n",
    "        artifact.add_file(f'last_model_{wandb.run.id}.pt')\n",
    "        wandb.log_artifact(artifact)\n",
    "        wandb.finish()\n",
    "        exit(0)\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "# Sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'metric': {'name': 'valid_word_acc', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'emb_dim': {'values': [128]},\n",
    "        'hid_dim': {'values': [128,256]},\n",
    "        'enc_layers': {'values': [1]},\n",
    "        'dec_layers': {'values': [1]},\n",
    "        'cell_type': {'values': ['RNN', 'GRU', 'LSTM']},\n",
    "        'dropout': {'values': [0.2, 0.3]},\n",
    "        'beam_size': {'values': [1, 3, 5]},\n",
    "        'learning_rate': {'values': [5e-4, 1e-3, 5e-3]},\n",
    "        'batch_size': {'values': [8, 16]},\n",
    "        'teacher_forcing': {'values': [0.3, 0.5, 0.7]},\n",
    "        'optimizer': {'values': ['Adam', 'RMSprop', 'AdamW']},\n",
    "        'grad_clip': {'values': [5]},\n",
    "        'weight_decay': {'values': [1e-6]},\n",
    "        'bidirectional': {'values': [False]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"transliteration-seq2seq-attention\")\n",
    "    wandb.agent(sweep_id, function=train_sweep, count=50)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

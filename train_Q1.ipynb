{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec7672-8598-458c-b60c-3246e7b22934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import os\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "from tabulate import tabulate\n",
    "import uuid\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Character-level dataset class\n",
    "class TransliterationDataset(Dataset):\n",
    "    def __init__(self, data_file, max_len=500, vocab=None):\n",
    "        self.df = pd.read_csv(data_file, sep='\\t', header=None)\n",
    "        self.src_texts = self.df[1].astype(str).tolist()\n",
    "        self.tgt_texts = self.df[0].astype(str).tolist()\n",
    "        self.max_len = max_len\n",
    "        if vocab is None:\n",
    "            self.src_vocab = self.build_vocab(self.src_texts)\n",
    "            self.tgt_vocab = self.build_vocab(self.tgt_texts)\n",
    "        else:\n",
    "            self.src_vocab, self.tgt_vocab = vocab\n",
    "        self.src_vocab_size = len(self.src_vocab)\n",
    "        self.tgt_vocab_size = len(self.tgt_vocab)\n",
    "        self.src_pad_idx = self.src_vocab['<pad>']\n",
    "        self.tgt_pad_idx = self.tgt_vocab['<pad>']\n",
    "        self.tgt_sos_idx = self.tgt_vocab['<sos>']\n",
    "        self.tgt_eos_idx = self.tgt_vocab['<eos>']\n",
    "        self.tgt_inv_vocab = {i: char for char, i in self.tgt_vocab.items()}\n",
    "    \n",
    "    def build_vocab(self, texts):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            counter.update(list(text))\n",
    "        vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "        vocab.update({char: i+3 for i, char in enumerate(sorted(counter.keys()))})\n",
    "        return vocab\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.src_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src_texts[idx]\n",
    "        tgt = self.tgt_texts[idx]\n",
    "        src_indices = [self.src_vocab.get(char, self.src_vocab['<pad>']) for char in src]\n",
    "        tgt_indices = [self.tgt_sos_idx] + [self.tgt_vocab.get(char, self.tgt_vocab['<pad>']) for char in tgt] + [self.tgt_eos_idx]\n",
    "        return torch.tensor(src_indices), torch.tensor(tgt_indices), src, tgt\n",
    "\n",
    "# Encoder class\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, cell_type, dropout, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_class(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout if n_layers > 1 else 0, bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        if self.cell_type == 'LSTM':\n",
    "            outputs, (hidden, cell) = self.rnn(embedded)\n",
    "            if self.bidirectional:\n",
    "                # Reshape hidden and cell: [n_layers * 2, batch_size, hid_dim] -> [n_layers, batch_size, hid_dim * 2]\n",
    "                hidden = hidden.view(self.n_layers, 2, -1, self.hid_dim)\n",
    "                cell = cell.view(self.n_layers, 2, -1, self.hid_dim)\n",
    "                hidden = torch.cat((hidden[:, 0, :, :], hidden[:, 1, :, :]), dim=-1)\n",
    "                cell = torch.cat((cell[:, 0, :, :], cell[:, 1, :, :]), dim=-1)\n",
    "            return hidden, cell\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedded)\n",
    "            if self.bidirectional:\n",
    "                hidden = hidden.view(self.n_layers, 2, -1, self.hid_dim)\n",
    "                hidden = torch.cat((hidden[:, 0, :, :], hidden[:, 1, :, :]), dim=-1)\n",
    "            return hidden\n",
    "\n",
    "# Decoder class\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, cell_type, dropout, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n",
    "        input_dim = emb_dim\n",
    "        self.rnn = rnn_class(input_dim, hid_dim, num_layers=n_layers, dropout=dropout if n_layers > 1 else 0)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input, hidden, cell=None):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        if self.cell_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# Seq2Seq class\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.bidirectional = encoder.bidirectional\n",
    "        if self.bidirectional:\n",
    "            self.fc_hidden = nn.Linear(encoder.hid_dim * 2, decoder.hid_dim)\n",
    "            if encoder.cell_type == 'LSTM':\n",
    "                self.fc_cell = nn.Linear(encoder.hid_dim * 2, decoder.hid_dim)\n",
    "    \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            hidden, cell = self.encoder(src)\n",
    "            if self.bidirectional:\n",
    "                hidden = self.fc_hidden(hidden)\n",
    "                cell = self.fc_cell(cell)\n",
    "        else:\n",
    "            hidden = self.encoder(src)\n",
    "            if self.bidirectional:\n",
    "                hidden = self.fc_hidden(hidden)\n",
    "            cell = None\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs\n",
    "    \n",
    "    def predict(self, src, max_len=50, sos_idx=1, eos_idx=2):\n",
    "        self.eval()\n",
    "        src = src.to(self.device)\n",
    "        batch_size = src.shape[1] if len(src.shape) > 1 else 1\n",
    "        outputs = torch.zeros(max_len, batch_size).long().to(self.device)\n",
    "        outputs[0] = sos_idx\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            hidden, cell = self.encoder(src)\n",
    "            if self.bidirectional:\n",
    "                hidden = self.fc_hidden(hidden)\n",
    "                cell = self.fc_cell(cell)\n",
    "        else:\n",
    "            hidden = self.encoder(src)\n",
    "            if self.bidirectional:\n",
    "                hidden = self.fc_hidden(hidden)\n",
    "            cell = None\n",
    "        input = torch.LongTensor([sos_idx] * batch_size).to(self.device)\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            top1 = output.argmax(1)\n",
    "            outputs[t] = top1\n",
    "            input = top1\n",
    "            if all(top1 == eos_idx):\n",
    "                outputs = outputs[:t+1]\n",
    "                break\n",
    "        return outputs\n",
    "\n",
    "# Accuracy metrics\n",
    "def calculate_accuracies(model, iterator, device, dataset):\n",
    "    model.eval()\n",
    "    char_correct = 0\n",
    "    char_total = 0\n",
    "    word_correct = 0\n",
    "    word_total = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, src_text, tgt_text in iterator:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model.predict(src, max_len=dataset.max_len, \n",
    "                                 sos_idx=dataset.tgt_sos_idx, eos_idx=dataset.tgt_eos_idx)\n",
    "            for i in range(src.shape[1] if len(src.shape) > 1 else 1):\n",
    "                pred_seq = output[:, i].cpu().numpy()\n",
    "                trg_seq = trg[:, i].cpu().numpy() if len(src.shape) > 1 else trg.cpu().numpy()\n",
    "                pred_chars = [dataset.tgt_inv_vocab.get(idx, '<unk>') for idx in pred_seq if idx != dataset.tgt_eos_idx and idx != dataset.tgt_sos_idx]\n",
    "                trg_chars = [dataset.tgt_inv_vocab.get(idx, '<unk>') for idx in trg_seq if idx != dataset.tgt_eos_idx and idx != dataset.tgt_sos_idx]\n",
    "                char_correct += sum(p == t for p, t in zip(pred_chars, trg_chars))\n",
    "                char_total += len(trg_chars)\n",
    "                pred_word = ''.join(pred_chars)\n",
    "                trg_word = ''.join(trg_chars)\n",
    "                word_correct += pred_word == trg_word\n",
    "                word_total += 1\n",
    "    char_acc = char_correct / char_total if char_total > 0 else 0\n",
    "    word_acc = word_correct / word_total if word_total > 0 else 0\n",
    "    return char_acc, word_acc\n",
    "\n",
    "# Training function\n",
    "def train(model, iterator, optimizer, criterion, clip, device, dataset, epoch, max_epochs=20):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    teacher_forcing_ratio = max(0.5, 1.0 - (epoch / max_epochs) * 0.5)\n",
    "    for src, trg, _, _ in iterator:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    char_acc, word_acc = calculate_accuracies(model, iterator, device, dataset)\n",
    "    return epoch_loss / len(iterator), char_acc, word_acc\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, iterator, criterion, device, dataset):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, _, _ in iterator:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg, 0)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    char_acc, word_acc = calculate_accuracies(model, iterator, device, dataset)\n",
    "    return epoch_loss / len(iterator), char_acc, word_acc\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    src_tensors, tgt_tensors, src_texts, tgt_texts = zip(*batch)\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_tensors, batch_first=False, padding_value=0)\n",
    "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_tensors, batch_first=False, padding_value=0)\n",
    "    return src_padded, tgt_padded, list(src_texts), list(tgt_texts)\n",
    "\n",
    "# Training function for WandB sweep\n",
    "def train_sweep():\n",
    "    wandb.init()\n",
    "    hparams = wandb.config\n",
    "    \n",
    "    base_path = '/home/user/Downloads/dakshina_dataset_v1.0/hi/lexicons'\n",
    "    train_path = f'{base_path}/hi.translit.sampled.train.tsv'\n",
    "    dev_path = f'{base_path}/hi.translit.sampled.dev.tsv'\n",
    "    test_path = f'{base_path}/hi.translit.sampled.test.tsv'\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Build shared vocabulary\n",
    "    train_df = pd.read_csv(train_path, sep='\\t', header=None)\n",
    "    dev_df = pd.read_csv(dev_path, sep='\\t', header=None)\n",
    "    test_df = pd.read_csv(test_path, sep='\\t', header=None)\n",
    "    all_src_texts = train_df[1].astype(str).tolist() + dev_df[1].astype(str).tolist() + test_df[1].astype(str).tolist()\n",
    "    all_tgt_texts = train_df[0].astype(str).tolist() + dev_df[0].astype(str).tolist() + test_df[0].astype(str).tolist()\n",
    "    \n",
    "    temp_dataset = TransliterationDataset(train_path)\n",
    "    src_vocab = temp_dataset.build_vocab(all_src_texts)\n",
    "    tgt_vocab = temp_dataset.build_vocab(all_tgt_texts)\n",
    "    vocab = (src_vocab, tgt_vocab)\n",
    "    \n",
    "    # Initialize datasets\n",
    "    train_dataset = TransliterationDataset(train_path, vocab=vocab)\n",
    "    dev_dataset = TransliterationDataset(dev_path, vocab=vocab)\n",
    "    test_dataset = TransliterationDataset(test_path, vocab=vocab)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=hparams.batch_size, shuffle=True, \n",
    "                             collate_fn=collate_fn)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=hparams.batch_size, \n",
    "                           collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=hparams.batch_size, \n",
    "                            collate_fn=collate_fn)\n",
    "    \n",
    "    encoder = Encoder(\n",
    "        input_dim=train_dataset.src_vocab_size,\n",
    "        emb_dim=hparams.emb_dim,\n",
    "        hid_dim=hparams.hid_dim,\n",
    "        n_layers=hparams.enc_layers,\n",
    "        cell_type=hparams.cell_type,\n",
    "        dropout=hparams.dropout,\n",
    "        bidirectional=False\n",
    "    )\n",
    "    decoder = Decoder(\n",
    "        output_dim=train_dataset.tgt_vocab_size,\n",
    "        emb_dim=hparams.emb_dim,\n",
    "        hid_dim=hparams.hid_dim,\n",
    "        n_layers=hparams.dec_layers,\n",
    "        cell_type=hparams.cell_type,\n",
    "        dropout=hparams.dropout,\n",
    "        bidirectional=False\n",
    "    )\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    \n",
    "    optimizer_class = {'Adam': optim.Adam, 'RMSprop': optim.RMSprop, 'AdamW': optim.AdamW}[hparams.optimizer]\n",
    "    optimizer = optimizer_class(model.parameters(), lr=hparams.learning_rate, weight_decay=hparams.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=train_dataset.tgt_pad_idx)\n",
    "    \n",
    "    n_epochs = 50\n",
    "    best_valid_word_acc = 0\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss, train_char_acc, train_word_acc = train(model, train_loader, optimizer, \n",
    "                                                              criterion, hparams.grad_clip, device, train_dataset, epoch, n_epochs)\n",
    "            valid_loss, valid_char_acc, valid_word_acc = evaluate(model, dev_loader, criterion, device, dev_dataset)\n",
    "            wandb.log({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'train_char_acc': train_char_acc,\n",
    "                'train_word_acc': train_word_acc,\n",
    "                'valid_loss': valid_loss,\n",
    "                'valid_char_acc': valid_char_acc,\n",
    "                'valid_word_acc': valid_word_acc\n",
    "            })\n",
    "            print(f'Epoch: {epoch+1:02}')\n",
    "            print(f'\\tTrain Loss: {train_loss:.3f} | Char Acc: {train_char_acc:.3f} | Word Acc: {train_word_acc:.3f}')\n",
    "            print(f'\\tVal. Loss: {valid_loss:.3f} | Char Acc: {valid_char_acc:.3f} | Word Acc: {valid_word_acc:.3f}')\n",
    "            if valid_word_acc > best_valid_word_acc:\n",
    "                best_valid_word_acc = valid_word_acc\n",
    "                model_path = f'best_model_{wandb.run.id}.pt'\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                artifact = wandb.Artifact(f'model_{wandb.run.id}', type='model')\n",
    "                artifact.add_file(model_path)\n",
    "                wandb.log_artifact(artifact)\n",
    "        \n",
    "        model.load_state_dict(torch.load(f'best_model_{wandb.run.id}.pt'))\n",
    "        test_loss, test_char_acc, test_word_acc = evaluate(model, test_loader, criterion, device, test_dataset)\n",
    "        wandb.log({\n",
    "            'test_loss': test_loss,\n",
    "            'test_char_acc': test_char_acc,\n",
    "            'test_word_acc': test_word_acc\n",
    "        })\n",
    "        \n",
    "        model.eval()\n",
    "        samples = []\n",
    "        with torch.no_grad():\n",
    "            for src, trg, src_text, tgt_text in itertools.islice(test_loader, 5):\n",
    "                src = src.to(device)\n",
    "                output = model.predict(src, max_len=50, sos_idx=test_dataset.tgt_sos_idx, \n",
    "                                     eos_idx=test_dataset.tgt_eos_idx)\n",
    "                for i in range(src.shape[1] if len(src.shape) > 1 else 1):\n",
    "                    pred_seq = output[:, i].cpu().numpy()\n",
    "                    pred_word = ''.join([test_dataset.tgt_inv_vocab.get(idx, '<unk>') for idx in pred_seq \n",
    "                                        if idx != test_dataset.tgt_eos_idx and idx != test_dataset.tgt_sos_idx])\n",
    "                    tgt_word = tgt_text[i] if len(src.shape) > 1 else tgt_text\n",
    "                    samples.append({\n",
    "                        'Latin Input': src_text[i] if len(src.shape) > 1 else src_text,\n",
    "                        'Devanagari Target': tgt_word,\n",
    "                        'Devanagari Predicted': pred_word,\n",
    "                        'Correct': pred_word == tgt_word\n",
    "                    })\n",
    "        \n",
    "        headers = ['#', 'Latin Input', 'Devanagari Target', 'Devanagari Predicted', 'Correct']\n",
    "        table_data = [[i+1, s['Latin Input'], s['Devanagari Target'], s['Devanagari Predicted'], \n",
    "                       '✅' if s['Correct'] else '❌'] for i, s in enumerate(samples)]\n",
    "        wandb.log({'sample_predictions': wandb.Table(columns=headers, data=table_data)})\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"Training interrupted. Saving current model state...\")\n",
    "        model_path = f'last_model_{wandb.run.id}.pt'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        artifact = wandb.Artifact(f'last_model_{wandb.run.id}', type='model')\n",
    "        artifact.add_file(model_path)\n",
    "        wandb.log_artifact(artifact)\n",
    "        wandb.finish()\n",
    "        exit(0)\n",
    "    \n",
    "    wandb.finish()\n",
    "# Sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'metric': {'name': 'valid_word_acc', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'emb_dim': {'values': [128]},\n",
    "        'hid_dim': {'values': [256]},\n",
    "        'enc_layers': {'values': [1]},\n",
    "        'dec_layers': {'values': [1]},\n",
    "        'cell_type': {'values': ['GRU', 'LSTM','RNN']},\n",
    "        'dropout': {'values': [0.2, 0.3]},\n",
    "        'learning_rate': {'values': [1e-3, 5e-4]},\n",
    "        'batch_size': {'values': [16, 32]},\n",
    "        'optimizer': {'values': ['Adam', 'AdamW']},\n",
    "        'grad_clip': {'values': [5.0]},\n",
    "        'weight_decay': {'values': [ 1e-6]},\n",
    "        'bidirectional': {'values': [True]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"transliteration-seq2seq\")\n",
    "    wandb.agent(sweep_id, function=train_sweep, count=100)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
